{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41cd111-bc0c-4805-9034-b3b7cf5fd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32114a04-1557-42e4-924a-b808caf81ddf",
   "metadata": {},
   "source": [
    "# Цели\n",
    "### Pipeline\n",
    "### Пересмотреть препроцессинг (может быть, стоит разделить возраст людей на группы?)\n",
    "### Попробовать кросс валидацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c3f002-9ed2-48fa-a8db-70ea29019597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeSexToBinary(row):\n",
    "    if row.Sex == 'male': \n",
    "        row.Sex = 1\n",
    "    elif row.Sex == 'female':\n",
    "        row.Sex = 0\n",
    "    return row\n",
    "\n",
    "\n",
    "def data_preprocessing(data):\n",
    "    current_data = data.drop(['Name', 'Ticket', \"Cabin\"], axis = 1) #выбрасываем колонки с ненужными данным\n",
    "\n",
    "    object_cols = ['Embarked'] #имена колонок с категориальными значениями, которые будем преобразовывать в колонки с одним активным состоянием\n",
    "    imputer = SimpleImputer(strategy='most_frequent') \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output = False)\n",
    "\n",
    "    if 'Survived' in current_data.columns: \n",
    "        X = current_data.drop(['Survived'], axis = 1)\n",
    "        y = current_data['Survived']\n",
    "    else:\n",
    "        X = current_data\n",
    "\n",
    "    imputed_X = pd.DataFrame(imputer.fit_transform(X)) \n",
    "    imputed_X.columns = X.columns\n",
    "\n",
    "    OH_cols = pd.DataFrame(OH_encoder.fit_transform(imputed_X[object_cols]))\n",
    "    num_X = imputed_X.drop(object_cols, axis = 1)\n",
    "    OH_cols.index = imputed_X.index\n",
    "\n",
    "    imputed_OH_X = pd.concat([num_X, OH_cols], axis = 1)\n",
    "    imputed_OH_X = imputed_OH_X.apply(changeSexToBinary, axis = 'columns')\n",
    "\n",
    "    imputed_OH_X.columns = imputed_OH_X.columns.astype(str)\n",
    "\n",
    "    if 'Survived' in current_data.columns:\n",
    "        return imputed_OH_X, y\n",
    "    else:\n",
    "        return imputed_OH_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd37f21d-98bb-4144-b8b0-ab6d19ce1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "X, y = data_preprocessing(train_data)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "my_model = LogisticRegression(max_iter=10000);\n",
    "my_model.fit(X_train, y_train);\n",
    "\n",
    "preds = my_model.predict(X_valid);\n",
    "print(accuracy_score(preds, y_valid));\n",
    "\n",
    "\n",
    "# test_data = pd.read_csv('./data/test.csv')\n",
    "# X_test = data_preprocessing(test_data)\n",
    "\n",
    "# predicts = my_model.predict(X_test)\n",
    "# outp = pd.DataFrame({\"PassengerId\": test_data['PassengerId'], \"Survived\": predicts})\n",
    "# outp.to_csv('./submissions/SubmissionLogFinal6.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# my_model = XGBClassifier(max_depth = 2, learning_rate = 0.1, early_stopping_rounds = 5)\n",
    "# my_model.fit(X_train, y_train,\n",
    "#             eval_set = [(X_valid, y_valid)],\n",
    "#             verbose=False);\n",
    "\n",
    "# curr_preds = my_model.predict(X_valid)\n",
    "# print(accuracy_score(curr_preds, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c22154-eed6-4575-aa4b-66ebef58ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testXGBClass(max_depth:int, learning_rate: float, early_stopping_rounds: int)->float:\n",
    "    X_valid_1, X_valid_2, y_valid_1, y_valid_2 = train_test_split(X_valid, y_valid, test_size = 0.5, random_state = 1)\n",
    "    \n",
    "    my_model = XGBClassifier(max_depth = max_depth, learning_rate = learning_rate, early_stopping_rounds = early_stopping_rounds)\n",
    "    my_model.fit(X_train, y_train,\n",
    "                eval_set=[(X_valid_1, y_valid_1)],\n",
    "                verbose=False)\n",
    "    \n",
    "    curr_preds = my_model.predict(X_valid_2)\n",
    "    return accuracy_score(curr_preds, y_valid_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de88eec-2c4c-4619-b86e-e7ac07fbcf34",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m curr_rate \u001b[38;5;129;01min\u001b[39;00m learning_rate_list:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m curr_rounds \u001b[38;5;129;01min\u001b[39;00m early_stopping_rounds_list:\n\u001b[1;32m---> 11\u001b[0m         curr_acc_score \u001b[38;5;241m=\u001b[39m \u001b[43mtestXGBClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m curr_acc_score \u001b[38;5;241m>\u001b[39m max_accuracy:\n\u001b[0;32m     13\u001b[0m             max_accuracy \u001b[38;5;241m=\u001b[39m curr_acc_score\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mtestXGBClass\u001b[1;34m(max_depth, learning_rate, early_stopping_rounds)\u001b[0m\n\u001b[0;32m      2\u001b[0m X_valid_1, X_valid_2, y_valid_1, y_valid_2 \u001b[38;5;241m=\u001b[39m train_test_split(X_valid, y_valid, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m my_model \u001b[38;5;241m=\u001b[39m XGBClassifier(max_depth \u001b[38;5;241m=\u001b[39m max_depth, learning_rate \u001b[38;5;241m=\u001b[39m learning_rate, early_stopping_rounds \u001b[38;5;241m=\u001b[39m early_stopping_rounds)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m curr_preds \u001b[38;5;241m=\u001b[39m my_model\u001b[38;5;241m.\u001b[39mpredict(X_valid_2)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(curr_preds, y_valid_2)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1515\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1487\u001b[0m (\n\u001b[0;32m   1488\u001b[0m     model,\n\u001b[0;32m   1489\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1495\u001b[0m )\n\u001b[0;32m   1496\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1497\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1498\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1512\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1513\u001b[0m )\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2049\u001b[0m     _check_call(\n\u001b[1;32m-> 2050\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2053\u001b[0m     )\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2055\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_depth_list = [i for i in range (2, 25)]\n",
    "learning_rate_list = [0.03, 0.05, 0.07, 0.1, 0.12, 0.15, 0.18, 0.2, 0.22, 0.25, 0.27, 0.3 ]\n",
    "early_stopping_rounds_list = [i for i in range(3, 15, 2)]\n",
    "\n",
    "max_accuracy = 0\n",
    "ans_list = []\n",
    "\n",
    "for curr_depth in max_depth_list:\n",
    "    for curr_rate in learning_rate_list:\n",
    "        for curr_rounds in early_stopping_rounds_list:\n",
    "            curr_acc_score = testXGBClass(curr_depth, curr_rate, curr_rounds)\n",
    "            if curr_acc_score > max_accuracy:\n",
    "                max_accuracy = curr_acc_score\n",
    "                ans_list = [curr_depth, curr_rate, curr_rounds]\n",
    "print(max_accuracy, ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48247f-5621-493d-9542-2519fa8685aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model = XGBClassifier(max_depth = 3, learning_rate = 0.3, early_stopping_rounds = 5)\n",
    "# my_model.fit(X_train, y_train, \n",
    "#             eval_set=[(X_valid, y_valid)],\n",
    "#             verbose=False)\n",
    "\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "X_test = data_preprocessing(test_data)\n",
    "\n",
    "predicts = my_model.predict(X_test)\n",
    "outp = pd.DataFrame({\"PassengerId\": test_data['PassengerId'], \"Survived\": predicts})\n",
    "outp.to_csv('./submissions/SubmissionXGBFinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4d787-eb9b-41a6-a17c-5f2bc0566eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7017b-7794-4c45-8cbe-d8bdd563556a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
